{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_small.csv\", header=None, names=[\"ID_code\", \"target\"]+[\"var_\"+str(i) for i in range(200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train_data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 20,226\n",
      "Trainable params: 20,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build autoencoder\n",
    "# https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu', input_shape=[200]))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.values[:,2:]\n",
    "X_val = val.values[:,2:]\n",
    "Y_train = train.values[:,1]\n",
    "Y_train = Y_train.astype('int')\n",
    "Y_val = val.values[:,1]\n",
    "Y_val = Y_val.astype('int')\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "x_val_minmax = min_max_scaler.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63051/63051 [==============================] - 2s 36us/sample - loss: 1.1965\n",
      "Epoch 2/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.9818\n",
      "Epoch 3/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.9249\n",
      "Epoch 4/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.9069\n",
      "Epoch 5/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.9141\n",
      "Epoch 6/100\n",
      "63051/63051 [==============================] - 1s 14us/sample - loss: 0.9111\n",
      "Epoch 7/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8894\n",
      "Epoch 8/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.9086\n",
      "Epoch 9/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8950\n",
      "Epoch 10/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8892\n",
      "Epoch 11/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8937\n",
      "Epoch 12/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8916\n",
      "Epoch 13/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8863\n",
      "Epoch 14/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.9080\n",
      "Epoch 15/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8916\n",
      "Epoch 16/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8843\n",
      "Epoch 17/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8907\n",
      "Epoch 18/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8943\n",
      "Epoch 19/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8814\n",
      "Epoch 20/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8896\n",
      "Epoch 21/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8862\n",
      "Epoch 22/100\n",
      "63051/63051 [==============================] - 1s 14us/sample - loss: 0.8869\n",
      "Epoch 23/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8760\n",
      "Epoch 24/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8806\n",
      "Epoch 25/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8909\n",
      "Epoch 26/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8727\n",
      "Epoch 27/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8892\n",
      "Epoch 28/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8789\n",
      "Epoch 29/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8940\n",
      "Epoch 30/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8676\n",
      "Epoch 31/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8700\n",
      "Epoch 32/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8815\n",
      "Epoch 33/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8632\n",
      "Epoch 34/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8691\n",
      "Epoch 35/100\n",
      "63051/63051 [==============================] - 1s 14us/sample - loss: 0.8645\n",
      "Epoch 36/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8618\n",
      "Epoch 37/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8647\n",
      "Epoch 38/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8618\n",
      "Epoch 39/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8667\n",
      "Epoch 40/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8541\n",
      "Epoch 41/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8483\n",
      "Epoch 42/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8552\n",
      "Epoch 43/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8425\n",
      "Epoch 44/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8486\n",
      "Epoch 45/100\n",
      "63051/63051 [==============================] - 1s 11us/sample - loss: 0.8427\n",
      "Epoch 46/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8436\n",
      "Epoch 47/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8438\n",
      "Epoch 48/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8372\n",
      "Epoch 49/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8345\n",
      "Epoch 50/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8320\n",
      "Epoch 51/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8311\n",
      "Epoch 52/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8350\n",
      "Epoch 53/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8407\n",
      "Epoch 54/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8250\n",
      "Epoch 55/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8277\n",
      "Epoch 56/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8125\n",
      "Epoch 57/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8161\n",
      "Epoch 58/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8062\n",
      "Epoch 59/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8045\n",
      "Epoch 60/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8097\n",
      "Epoch 61/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.8111\n",
      "Epoch 62/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7944\n",
      "Epoch 63/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.8049\n",
      "Epoch 64/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.7906\n",
      "Epoch 65/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7898\n",
      "Epoch 66/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7958\n",
      "Epoch 67/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.7871\n",
      "Epoch 68/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7804\n",
      "Epoch 69/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7843\n",
      "Epoch 70/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7830\n",
      "Epoch 71/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7829\n",
      "Epoch 72/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7603\n",
      "Epoch 73/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7751\n",
      "Epoch 74/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7709\n",
      "Epoch 75/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.7679\n",
      "Epoch 76/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7668\n",
      "Epoch 77/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.7585\n",
      "Epoch 78/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7447\n",
      "Epoch 79/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.7606\n",
      "Epoch 80/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7562\n",
      "Epoch 81/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.7350\n",
      "Epoch 82/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.7423\n",
      "Epoch 83/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7462\n",
      "Epoch 84/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7323\n",
      "Epoch 85/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7193\n",
      "Epoch 86/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.7187\n",
      "Epoch 87/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7314\n",
      "Epoch 88/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.7063\n",
      "Epoch 89/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7223\n",
      "Epoch 90/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.7391\n",
      "Epoch 91/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.7108\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.7050\n",
      "Epoch 93/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.6937\n",
      "Epoch 94/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.7101\n",
      "Epoch 95/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.6966\n",
      "Epoch 96/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.6927\n",
      "Epoch 97/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.6844\n",
      "Epoch 98/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.6846\n",
      "Epoch 99/100\n",
      "63051/63051 [==============================] - 1s 12us/sample - loss: 0.6870\n",
      "Epoch 100/100\n",
      "63051/63051 [==============================] - 1s 13us/sample - loss: 0.6878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f602f202240>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = {0: 1., 1: 10}\n",
    "targets = np.array(Y_train).reshape(-1)\n",
    "one_hot_targets = np.eye(2)[targets]\n",
    "model.fit(x_train_minmax, one_hot_targets, batch_size=512, class_weight=class_weight, epochs=100, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
      "53467  train_152456       0  15.2660  1.5756  17.4416  6.3997  10.8700   \n",
      "19103   train_54311       0  12.3749 -1.9334  12.1989  3.4742  10.3276   \n",
      "3949    train_11144       0  10.1342 -7.5167   8.4104  6.2085   9.9965   \n",
      "69082  train_197138       0   7.2032 -6.2748   9.2712  7.7527  11.9160   \n",
      "51398  train_146657       0  17.2041 -4.7456  13.4534  6.5172  11.6681   \n",
      "\n",
      "         var_5   var_6    var_7  ...  var_222  var_223  var_224   var_225  \\\n",
      "53467  -9.4275  4.6510  23.6536  ...     -0.0     -0.0     -0.0  0.945553   \n",
      "19103   3.9727  7.6310  20.2776  ...     -0.0     -0.0     -0.0  0.101307   \n",
      "3949  -16.1401  6.2026  18.5395  ...     -0.0     -0.0     -0.0  2.045673   \n",
      "69082 -12.3365  6.0507  10.8860  ...     -0.0     -0.0     -0.0  0.838510   \n",
      "51398   3.0272  5.8702  10.0972  ...     -0.0     -0.0     -0.0 -0.000000   \n",
      "\n",
      "        var_226   var_227  var_228   var_229  var_230  var_231  \n",
      "53467 -0.000000 -0.000000     -0.0  0.972032     -0.0     -0.0  \n",
      "19103  0.069684  0.278782     -0.0  0.214716     -0.0     -0.0  \n",
      "3949  -0.000000 -0.000000     -0.0  1.632957     -0.0     -0.0  \n",
      "69082 -0.000000  0.098253     -0.0  0.717716     -0.0     -0.0  \n",
      "51398  0.192822  0.450403     -0.0  0.290542     -0.0     -0.0  \n",
      "\n",
      "[5 rows x 234 columns]\n",
      "            ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
      "65732  train_187528       0  14.5577  4.1362  10.2816  7.7759  11.2243   \n",
      "36298  train_103540       0  11.6252  1.2038  12.1505  1.8401  13.8473   \n",
      "62151  train_177380       1  18.6619 -1.1500  16.0312  4.2826  13.8049   \n",
      "54510  train_155441       0   9.8315  1.8357   9.5048  3.4314  10.0946   \n",
      "45218  train_129028       0  13.2301 -0.2059  11.9304  4.4345   9.6822   \n",
      "\n",
      "         var_5   var_6    var_7  ...   var_222  var_223  var_224   var_225  \\\n",
      "65732  -2.6076  5.2965  20.0472  ... -0.000000     -0.0     -0.0  0.675199   \n",
      "36298  -8.0119  6.8960  14.2452  ... -0.000000     -0.0     -0.0  0.263825   \n",
      "62151 -18.1913  6.1855  14.5947  ...  0.740079     -0.0     -0.0 -0.000000   \n",
      "54510  -6.6671  4.2817  14.1426  ... -0.000000     -0.0     -0.0  0.499053   \n",
      "45218  -7.8937  6.3287  13.6176  ... -0.000000     -0.0     -0.0  1.334380   \n",
      "\n",
      "        var_226   var_227  var_228   var_229  var_230  var_231  \n",
      "65732 -0.000000  0.025467     -0.0  0.810348     -0.0     -0.0  \n",
      "36298 -0.000000  0.116184     -0.0  0.852812     -0.0     -0.0  \n",
      "62151  1.542543  1.781887     -0.0 -0.000000     -0.0     -0.0  \n",
      "54510 -0.000000  0.133255     -0.0  0.469704     -0.0     -0.0  \n",
      "45218 -0.000000 -0.000000     -0.0  1.094394     -0.0     -0.0  \n",
      "\n",
      "[5 rows x 234 columns]\n"
     ]
    }
   ],
   "source": [
    "# get output from last hidden layer\n",
    "last_hidden_output = tf.keras.backend.function([model.layers[0].input], [model.layers[-2].output])\n",
    "\n",
    "train_pluss = train.copy()\n",
    "val_pluss = val.copy()\n",
    "for i, row in enumerate(np.array(last_hidden_output(x_train_minmax)).T):\n",
    "    train_pluss[(\"var_\"+str(i+200))] = row\n",
    "for i, row in enumerate(np.array(last_hidden_output(x_val_minmax)).T):\n",
    "    val_pluss[(\"var_\"+str(i+200))] = row\n",
    "    \n",
    "print(train_pluss.head())\n",
    "print(val_pluss.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters are from grid search and experimentation\n",
    "param = {\n",
    "    'bagging_freq': 4,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.1,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc', \n",
    "    'min_data_in_leaf': 50,\n",
    "    'min_sum_hessian_in_leaf': 10,\n",
    "    'num_leaves': 50,\n",
    "    'min_gain_to_split': 1,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary',\n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.977118\tvalid_1's auc: 0.849413\n",
      "[2000]\ttraining's auc: 0.995132\tvalid_1's auc: 0.852779\n",
      "[3000]\ttraining's auc: 0.998837\tvalid_1's auc: 0.854417\n",
      "[4000]\ttraining's auc: 0.999495\tvalid_1's auc: 0.855253\n",
      "[5000]\ttraining's auc: 0.999678\tvalid_1's auc: 0.856031\n",
      "[6000]\ttraining's auc: 0.999772\tvalid_1's auc: 0.856627\n",
      "[7000]\ttraining's auc: 0.999822\tvalid_1's auc: 0.856579\n",
      "[8000]\ttraining's auc: 0.999854\tvalid_1's auc: 0.856597\n",
      "[9000]\ttraining's auc: 0.999876\tvalid_1's auc: 0.85682\n",
      "[10000]\ttraining's auc: 0.999894\tvalid_1's auc: 0.857106\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\ttraining's auc: 0.999894\tvalid_1's auc: 0.857106\n"
     ]
    }
   ],
   "source": [
    "features = [c for c in train_pluss.columns if c not in [\"ID_code\", \"target\"]]\n",
    "\n",
    "# using lightbm over catboost because no categorical features\n",
    "lightbm_train = lgb.Dataset(train_pluss[features], label=train_pluss[\"target\"])\n",
    "lightbm_val = lgb.Dataset(val_pluss[features], label=val_pluss[\"target\"])\n",
    "clf = lgb.train(param, lightbm_train, 100000, valid_sets = [lightbm_train, lightbm_val], verbose_eval=1000, early_stopping_rounds = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9931852355368357\n",
      "0.7184577821714264\n"
     ]
    }
   ],
   "source": [
    "# print some information to get an idea of how well it worked\n",
    "train_predict = clf.predict(train_pluss[features], num_iteration=clf.best_iteration)\n",
    "train_predict_binary = list(map(lambda x : math.floor(x+0.5), train_predict))\n",
    "print(roc_auc_score(Y_train, train_predict_binary))\n",
    "\n",
    "val_predict = clf.predict(val_pluss[features], num_iteration=clf.best_iteration)\n",
    "val_predict_binary = list(map(lambda x : math.floor(x+0.5), val_predict))\n",
    "print(roc_auc_score(Y_val, val_predict_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID_code    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
      "0   train_0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
      "1   train_3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
      "2   train_7  13.5580 -7.9881  13.8776  7.5985   8.6543  0.8310  5.6890   \n",
      "3  train_12   8.7671 -4.6154   9.7242  7.4242   9.0254  1.4247  6.2815   \n",
      "4  train_14  13.8080  5.0514  17.2611  8.5120  12.8517 -9.1622  5.7327   \n",
      "\n",
      "     var_7   var_8  ...  var_222  var_223  var_224   var_225   var_226  \\\n",
      "0  18.6266 -4.9200  ...     -0.0     -0.0     -0.0  0.667717 -0.000000   \n",
      "1  14.9250 -5.8609  ...     -0.0     -0.0     -0.0 -0.000000  0.489251   \n",
      "2  22.3262  5.0647  ...     -0.0     -0.0     -0.0  0.589201 -0.000000   \n",
      "3  12.3143  5.6964  ...     -0.0     -0.0     -0.0  1.935561 -0.000000   \n",
      "4  21.0517 -4.5117  ...     -0.0     -0.0     -0.0  0.987471 -0.000000   \n",
      "\n",
      "    var_227  var_228   var_229  var_230  var_231  \n",
      "0  0.071230     -0.0  0.585236     -0.0     -0.0  \n",
      "1  0.617416     -0.0  0.027730     -0.0     -0.0  \n",
      "2  0.003580     -0.0  0.737840     -0.0     -0.0  \n",
      "3 -0.000000     -0.0  1.603479     -0.0     -0.0  \n",
      "4 -0.000000     -0.0  0.822487     -0.0     -0.0  \n",
      "\n",
      "[5 rows x 233 columns]\n"
     ]
    }
   ],
   "source": [
    "X_test = test_data.values[:,1:]\n",
    "x_test_minmax = min_max_scaler.fit_transform(X_test)\n",
    "\n",
    "test_pluss = test_data.copy()\n",
    "for i, row in enumerate(np.array(last_hidden_output(x_test_minmax)).T):\n",
    "    test_pluss[(\"var_\"+str(i+200))] = row\n",
    "print(test_pluss.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06639548990223364\n"
     ]
    }
   ],
   "source": [
    "test_predict = clf.predict(test_pluss[features], num_iteration=clf.best_iteration)\n",
    "test_predict_binary = list(map(lambda x : math.floor(x+0.5), test_predict))\n",
    "print(sum(test_predict_binary)/len(test_predict_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test predictions to csv file with no headers\n",
    "submission_df = pd.DataFrame(test_predict_binary)\n",
    "submission_df.to_csv(\"submission.csv\", encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
