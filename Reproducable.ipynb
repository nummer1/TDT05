{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import lightgbm as lgb\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_small.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters are from grid search and experimentation\n",
    "param = {\n",
    "    'bagging_freq': 4, # seems to work\n",
    "    'bagging_fraction': 0.4, # seems to work ... 0.5\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.1, # from grid search and seems to work ... 0.1\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1, # no max depth\n",
    "    'metric':'auc', \n",
    "    'min_data_in_leaf': 200, # limit overfitting ... 40\n",
    "    'min_sum_hessian_in_leaf': 0.01, # overfitting\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary',\n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.948475\tvalid_1's auc: 0.885146\n",
      "[2000]\ttraining's auc: 0.970019\tvalid_1's auc: 0.891297\n",
      "[3000]\ttraining's auc: 0.983462\tvalid_1's auc: 0.892473\n",
      "[4000]\ttraining's auc: 0.991967\tvalid_1's auc: 0.893486\n",
      "[5000]\ttraining's auc: 0.996744\tvalid_1's auc: 0.893782\n",
      "[6000]\ttraining's auc: 0.998903\tvalid_1's auc: 0.892727\n",
      "[7000]\ttraining's auc: 0.999718\tvalid_1's auc: 0.892321\n",
      "Early stopping, best iteration is:\n",
      "[4532]\ttraining's auc: 0.994894\tvalid_1's auc: 0.894185\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.948841\tvalid_1's auc: 0.884462\n",
      "[2000]\ttraining's auc: 0.97013\tvalid_1's auc: 0.887839\n",
      "[3000]\ttraining's auc: 0.983676\tvalid_1's auc: 0.887722\n",
      "[4000]\ttraining's auc: 0.992084\tvalid_1's auc: 0.887792\n",
      "[5000]\ttraining's auc: 0.996795\tvalid_1's auc: 0.887019\n",
      "Early stopping, best iteration is:\n",
      "[2279]\ttraining's auc: 0.974582\tvalid_1's auc: 0.888429\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.949125\tvalid_1's auc: 0.878773\n",
      "[2000]\ttraining's auc: 0.970499\tvalid_1's auc: 0.883715\n",
      "[3000]\ttraining's auc: 0.983978\tvalid_1's auc: 0.8854\n",
      "[4000]\ttraining's auc: 0.992274\tvalid_1's auc: 0.885861\n",
      "[5000]\ttraining's auc: 0.996965\tvalid_1's auc: 0.886464\n",
      "[6000]\ttraining's auc: 0.999002\tvalid_1's auc: 0.886465\n",
      "[7000]\ttraining's auc: 0.99974\tvalid_1's auc: 0.886251\n",
      "[8000]\ttraining's auc: 0.999943\tvalid_1's auc: 0.885183\n",
      "Early stopping, best iteration is:\n",
      "[5670]\ttraining's auc: 0.998539\tvalid_1's auc: 0.886857\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.948784\tvalid_1's auc: 0.885861\n",
      "[2000]\ttraining's auc: 0.969933\tvalid_1's auc: 0.891983\n",
      "[3000]\ttraining's auc: 0.983493\tvalid_1's auc: 0.893322\n",
      "[4000]\ttraining's auc: 0.992021\tvalid_1's auc: 0.892554\n",
      "[5000]\ttraining's auc: 0.996787\tvalid_1's auc: 0.89212\n",
      "Early stopping, best iteration is:\n",
      "[2826]\ttraining's auc: 0.981471\tvalid_1's auc: 0.893845\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.948431\tvalid_1's auc: 0.886841\n",
      "[2000]\ttraining's auc: 0.97001\tvalid_1's auc: 0.893291\n",
      "[3000]\ttraining's auc: 0.98352\tvalid_1's auc: 0.894269\n",
      "[4000]\ttraining's auc: 0.992216\tvalid_1's auc: 0.894342\n",
      "[5000]\ttraining's auc: 0.996821\tvalid_1's auc: 0.893776\n",
      "[6000]\ttraining's auc: 0.999006\tvalid_1's auc: 0.89297\n",
      "Early stopping, best iteration is:\n",
      "[3598]\ttraining's auc: 0.989261\tvalid_1's auc: 0.894701\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.9479\tvalid_1's auc: 0.890731\n",
      "[2000]\ttraining's auc: 0.969772\tvalid_1's auc: 0.898208\n",
      "[3000]\ttraining's auc: 0.983538\tvalid_1's auc: 0.899988\n",
      "[4000]\ttraining's auc: 0.992182\tvalid_1's auc: 0.899473\n",
      "[5000]\ttraining's auc: 0.996836\tvalid_1's auc: 0.898846\n",
      "[6000]\ttraining's auc: 0.998966\tvalid_1's auc: 0.898229\n",
      "Early stopping, best iteration is:\n",
      "[3038]\ttraining's auc: 0.98394\tvalid_1's auc: 0.900243\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.94837\tvalid_1's auc: 0.875668\n",
      "[2000]\ttraining's auc: 0.970078\tvalid_1's auc: 0.884181\n",
      "[3000]\ttraining's auc: 0.983521\tvalid_1's auc: 0.886789\n",
      "[4000]\ttraining's auc: 0.992084\tvalid_1's auc: 0.887071\n",
      "[5000]\ttraining's auc: 0.996727\tvalid_1's auc: 0.887143\n",
      "[6000]\ttraining's auc: 0.998929\tvalid_1's auc: 0.886593\n",
      "[7000]\ttraining's auc: 0.999716\tvalid_1's auc: 0.886191\n",
      "Early stopping, best iteration is:\n",
      "[4523]\ttraining's auc: 0.994871\tvalid_1's auc: 0.887423\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.947936\tvalid_1's auc: 0.890465\n",
      "[2000]\ttraining's auc: 0.96964\tvalid_1's auc: 0.898495\n",
      "[3000]\ttraining's auc: 0.983251\tvalid_1's auc: 0.899997\n",
      "[4000]\ttraining's auc: 0.992014\tvalid_1's auc: 0.900185\n",
      "[5000]\ttraining's auc: 0.996725\tvalid_1's auc: 0.899674\n",
      "[6000]\ttraining's auc: 0.998941\tvalid_1's auc: 0.89876\n",
      "Early stopping, best iteration is:\n",
      "[3751]\ttraining's auc: 0.99024\tvalid_1's auc: 0.900597\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.948587\tvalid_1's auc: 0.890923\n",
      "[2000]\ttraining's auc: 0.970153\tvalid_1's auc: 0.898255\n",
      "[3000]\ttraining's auc: 0.983562\tvalid_1's auc: 0.899539\n",
      "[4000]\ttraining's auc: 0.992223\tvalid_1's auc: 0.899393\n",
      "[5000]\ttraining's auc: 0.996797\tvalid_1's auc: 0.898317\n",
      "[6000]\ttraining's auc: 0.998983\tvalid_1's auc: 0.897675\n",
      "Early stopping, best iteration is:\n",
      "[3167]\ttraining's auc: 0.985341\tvalid_1's auc: 0.899792\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.948633\tvalid_1's auc: 0.88316\n",
      "[2000]\ttraining's auc: 0.970533\tvalid_1's auc: 0.889039\n",
      "[3000]\ttraining's auc: 0.983922\tvalid_1's auc: 0.890952\n",
      "[4000]\ttraining's auc: 0.992393\tvalid_1's auc: 0.891166\n",
      "[5000]\ttraining's auc: 0.996937\tvalid_1's auc: 0.891718\n",
      "[6000]\ttraining's auc: 0.999055\tvalid_1's auc: 0.891671\n",
      "[7000]\ttraining's auc: 0.99978\tvalid_1's auc: 0.89139\n",
      "[8000]\ttraining's auc: 0.999963\tvalid_1's auc: 0.89066\n",
      "Early stopping, best iteration is:\n",
      "[5667]\ttraining's auc: 0.998522\tvalid_1's auc: 0.891882\n"
     ]
    }
   ],
   "source": [
    "# get train and test feature names\n",
    "features = [c for c in train_data.columns if c not in [0, 1]]\n",
    "test_features = [c for c in test_data.columns if c not in ['ID_code']]\n",
    "\n",
    "test_predictions = np.zeros(len(test_data))\n",
    "train_predictions = np.zeros(len(train_data))\n",
    "# get target and training data\n",
    "target = train_data[1]\n",
    "train = train_data[features]\n",
    "\n",
    "# using 10 folds\n",
    "splits = 10\n",
    "skf = StratifiedKFold(n_splits=splits, shuffle=False)\n",
    "skf.get_n_splits(train, target)\n",
    "\n",
    "# using lightbm over catboost because no categorical features\n",
    "# using lightbm over xgboost because it's faster\n",
    "# train one lightbm for every fold, and sum up the predictions made by all folds on the test data set\n",
    "for train_index, val_index in skf.split(train, target):\n",
    "    train_fold = lgb.Dataset(train.iloc[train_index][features], label=target.iloc[train_index])\n",
    "    val_fold = lgb.Dataset(train.iloc[val_index][features], label=target.iloc[val_index])\n",
    "    clf = lgb.train(param, train_fold, 100000, valid_sets = [train_fold, val_fold], verbose_eval=1000, early_stopping_rounds = 3000)\n",
    "    \n",
    "    test_predictions += clf.predict(test_data[test_features], num_iteration=clf.best_iteration) / splits\n",
    "    train_predictions += clf.predict(train_data[features], num_iterations=clf.best_iteration) / splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7853014281046395\n",
      "0.030971240990508814\n"
     ]
    }
   ],
   "source": [
    "# print some information to get an idea of how well it worked\n",
    "train_predictions_binary = list(map(lambda x : math.floor(x+0.5), train_predictions))\n",
    "print(roc_auc_score(target.values, train_predictions_binary))\n",
    "\n",
    "test_predictions_binary = list(map(lambda x : math.floor(x+0.5), test_predictions))\n",
    "print(sum(test_predictions_binary)/len(test_predictions_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test predictions to csv file with no headers\n",
    "submission_df = pd.DataFrame(test_predictions_binary)\n",
    "submission_df.to_csv(\"submission.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
